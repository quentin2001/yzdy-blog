---
title: 到底什么是AI Agent，它和LLM什么区别？
description: '在应用之前先要了解ta是什么'
pubDate: 2025-11-23
cover: assets/cover.png
tags: ['AI', 'Agent', 'LLM']
recommend: true
---

### 💡 1. 先看一个例子

> **帮我订一个明天飞上海的机票，预算 500 元以内，并把可选方案发给我。**

---

#### 🧠 LLM 会怎么做？

LLM 会：

- 根据训练数据“猜测机票价格”
- 给你几段建议
- 但不会去查真实航班，更不会帮你下单

示例输出：

> 明天去上海的机票大约在 X~Y 元之间，建议去携程、飞猪搜索。

👉 本质上是在**说**，不是在**做**。

---

#### 🤖 Agent 会怎么做？

一个真正的 Agent 会：

1. **识别用户意图**
2. 调用真实 API 查询航班
3. 过滤预算范围
4. 生成可点击的可购买方案
5. 如果你授权，还能直接帮你下单

示例输出：

> 为你找到 3 个符合预算的航班：
>
> - 09: 20 — ¥468
> - 12: 55 — ¥495
> - 15: 40 — ¥499  
>   点击即可购买。

👉 **Agent 不是回复你，而是完成任务。**

---

### 🤖 2. 所以什么是 LLM？什么是 Agent？

很多人会误解：

- “带工具调用的 LLM = Agent”
- “能输出 ReAct 就是 Agent”

这些都是**不准确的**。下面做一个最干净、可落地的区分。

---

#### 🧠 **LLM：语言与推理引擎（会说，不会做）**

LLM 能：

- 生成文本
- 推理步骤
- 分析意图
- 生成 JSON schema
- 生成 SQL/代码

但 LLM **不能**：

- 真的执行动作
- 调用系统或 API（除非外部包装）
- 自己保存长期记忆
- 控制状态机
- 做可靠多轮任务

LLM 的本质：
**一个超级语言补全器 + 世界模型。**

---

### 🤖 **Agent：让 LLM 变成“能行动的智能体”**

Agent 必须具备完整闭环：

**感知 → 记忆 → 推理 → 工具调用 → 执行动作 → 观察结果 → 再推理 → 完成任务**

Agent =**LLM（大脑） + 工具（手脚） + 记忆系统 + 执行器 + 控制循环 + 安全边界**

如果用生物类比：

- **LLM = 大脑的语言与推理中枢**
- **Agent = 一个能行动的智能生命体**

#### 📌 一句话结论

> **LLM 决定“下一步应该做什么”。
> Agent 让这一步真实发生。**

---

### 🧱 3. Agent 的四大核心组件（结合上面的示例理解）

Agent 若要能“持续行动”，必须至少具备四类能力。

---

#### 3.1 感知 Perception

包括：

- API 返回数据
- 用户输入
- 文件内容
- 网页内容
- 传感器（机器人）

> LLM只能获取用户的输入

---

#### 3.2 记忆 Memory

分三类：

1. 短期（Working Memory）

- 当前对话
- 最近工具调用结果
- 正在进行的任务上下文

2. 中期（Episodic）

- 历史任务记录
- 失败重试日志
- 用户偏好

3. 长期（Semantic / 知识库）

- 文档
- 知识图谱
- 向量数据库

> 能否把记忆检索、写回、聚合，是 Agent 可靠性的重要分水岭。

---

### 3.3 工具与行动 Tools & Action

工具是真正执行任务的“手脚”：

- 天气 API
- 数据库操作
- 文件系统
- 浏览器自动化
- 代码执行器

> LLM 只是“决定用哪个工具”。

---

### 3.4 推理与规划 Reasoning & Planning

- 任务拆分
- 决定下一步要做什么
- 根据 observation 判断是否继续
- 自我纠错

> 这正是 ReAct 的核心价值。

---

### 🔥 4. 解答为什么 Agent 不是“带工具的 LLM”？

因为 Agent 解决的问题比 LLM 多得多。因为 Agent 背后有大量 LLM 之外的能力：

| 类别         | LLM               | Agent |
| ------------ | ----------------- | ----- |
| 推理         | ✔️                | ✔️    |
| 工具调用     | ❌                | ✔️    |
| 状态管理     | ❌                | ✔️    |
| 长期记忆     | ❌                | ✔️    |
| 对外行动     | ❌                | ✔️    |
| 自我修正     | ❌                | ✔️    |
| 多轮任务执行 | ❌                | ✔️    |
| 目标规划     | ❌（需要 prompt） | ✔️    |
| 安全控制     | ❌                | ✔️    |

一句话总结：

> **LLM 只能“说”，Agent 才能“做”。**

---

### ❗ 5. Agent 的工程难点（真实开发会遇到的）

现实中做 Agent，远比“加个工具调用”难得多：

- 上下文窗口有限 → 需要分段检索、摘要
- 工具调用失败 → 需要回滚、重试逻辑
- 幻觉问题 → 需要验证器（verifier）
- 成本与延迟 → LLM 调用昂贵
- 长期记忆管理困难
- 权限管理与安全风险

所有成熟 Agent 框架（LangChain、Meta Agent、OpenAI Agent API）都在解决这些问题。
这就是为什么成熟的 Agent 框架变得如此重要。

---

# **6. Agent 的标准工作循环：为什么它是所有 Agent 框架的“心脏”**

下面是标准的 Agent 循环伪代码（保留原来的结构，但讲得更明白）：

```python
while not done:
    # 1. 读取 “状态”
    context = memory.retrieve()

    # 2. 基于状态推理下一步
    thought = LLM.plan(context)

    # 3. 判断模型的意图是不是 “要执行工具”
    action = parse(thought)

    # 4. 执行工具
    result = tools.execute(action)

    # 5. 将观察写入记忆（外部长期状态）
    memory.write(action, result)

    # 6. 判断任务是否达成
    done = check_goal(result)
```

---

## 🔍 **这段循环为什么是 Agent 的核心？**

无论你使用的是：

- **LangGraph**
- **OpenAI Agent API**
- **ReAct**
- **AutoGen**
- **微软 Semantic Kernel**
- **Meta Agent**
- **Voyager / Devin / GPT-o1 Agentic 结构**

本质都要解决同一件事：

### **如何让一个只能“说话”的 LLM，变成一个能“持续完成任务”的系统？**

而要做到这一点，必须具备四个要素：

| 步骤       | Agent 必要能力 | 作用                         |
| ---------- | -------------- | ---------------------------- |
| 读取记忆   | 状态管理       | 让模型知道“我上一轮做到哪了” |
| 推理下一步 | 规划           | 决定下一步动作               |
| 执行工具   | 行动           | 让“语言输出”变成“真实动作”   |
| 写入记忆   | 状态更新       | 保证下一轮不会遗忘           |
| 判断完成   | 收敛机制       | 避免无限循环                 |

这五件事情就是 Agent 框架的“心脏”。
**谁实现得最稳定，谁就是最强的 Agent 框架。**

---

## 🧩 一个真实案例：自动化报销 Agent 如何利用这套循环？

假设你做一个公司内部的“报销助手 Agent”，它能：

1. 解析用户上传的发票
2. 自动分类
3. 查预算
4. 创建报销单
5. 提交审批

它的每一步都严格按上面循环：

### **第一轮**

- 读记忆：空
- 规划：用户上传了发票，我先 OCR
- 行动：调用 `read_invoice()`
- 写记忆：发票金额 = 320, 类别 = 交通

### **第二轮**

- 读记忆：发票金额、类别
- 规划：需要查预算剩余额度
- 行动：`get_budget(user_id)`

### **第三轮**

- 读记忆：预算 = 500
- 规划：可以创建报销单
- 行动：`create_ticket(320, "交通")`

### **第四轮**

- 读记忆：报销单编号
- 规划：提交审批
- 行动：`submit_approval(ticket_id)`
- 达成任务 → done

你会发现：

> **一个 Agent 不是“一次调用模型”，而是一套“带状态的推理—行动循环系统”。**

LLM 不是核心，
**循环 + 状态 才是核心。**

---

# **7. 三大 Agent 设计范式（更清晰、更工程化 + 新的分类扩展）**

这三类是现在业界默认的划分方式，我认可这种分类，并补充它们各自适用场景、弱点，以及实际案例。

---

## \*\*7.1 Reactive（反应式 Agent）

“没有规划，只是反射弧”\*\*

特征：

- 无长期规划
- 无工具推理链
- 输入 → 输出，完全即时反应
- 成本最低，延迟最短
- 不适合生命周期超过 2 步的任务

应用：

- 助手问答
- 简单命令执行
- 单步工具调用

案例：

- “帮我生成一封邮件草稿”
- “帮我总结这个 PDF”
- 大多数普通聊天机器人（并不是真 Agent）

一句话总结：

> **它不是 Agent，是“单步带工具的 LLM”。**
> 真正工程上的 Agent 不会是 reactive。

---

## \*\*7.2 Deliberative（规划式 Agent）

“会提前思考，会自己设计 Plan”\*\*

特征：

- 有明确的“思考阶段”（类似 GPT-o1）
- 会把目标拆成多步
- 再逐步去执行每个子任务
- 推理质量高但价格昂贵
- 常用于复杂、重要、不可出错的任务

应用：

- 代码调试、自动修复
- 法律文书分析
- 多文档推理、跨系统自动化任务
- 较强的企业级流程自动化

案例：

- **GPT-o1（本质是 Deliberative 推理引擎）**
- **Anthropic 的 “Slow Thinking” 模式**
- **"自动写 PRD → 自动生成测试用例 → 自动跑 CI" 这种任务链**

一句话总结：

> **规划式 Agent = 想好了再做。**
> 适合小心翼翼、需要推理深度的任务。

---

## \*\*7.3 ReAct（推理 + 行动）

“现代 Agent 默认模式”\*\*

特征：

- 思考（Thought）
- 行动（Action）
- 观察（Observation）
- 支持自我纠错
- 能进行多轮闭环，直到完成任务

优势：

- 在反应式和规划式之间找到最优折中
- 足够快，比 Deliberative 便宜很多
- 足够强，能处理多步骤任务

几乎所有现代 Agent 框架都基于 ReAct，包括：

- LangGraph
- Devin / Claude 3.7 工具链
- OpenAI Agent API
- AutoGPT（早期版本）

典型案例：

### 🌐 旅行规划 + 预订

- 查天气 → 查景点 → 查酒店 → 预订
  （每一步都要看前一步结果）

### 💼 自动客服工单处理

- 解析工单 → 分类 → 查询 FAQ → 调接口更新状态 → 生成回复

### 📈 数据分析 Agent

- 分析表格 → 生成 SQL → 调数据库 → 画图 → 总结

一句话总结：

> **ReAct = 能边做边想的智能体，是目前最实用的 Agent 范式。**

---

### 🧩 补充：还有哪些常见的 Agent 分类方式？

除了 industry 默认的“三分法”，学界和工程界还有其他分类：

---

#### 📌 **（1）按环境交互方式分类**

| 类型         | 特征               | 应用            |
| ------------ | ------------------ | --------------- |
| 单轮 Agent   | 一次输入，一次输出 | 普通助手        |
| 多轮 Agent   | 有循环，有状态     | 工作流自动化    |
| 交互式 Agent | 连续与环境互动     | 游戏 AI、机器人 |

---

#### 📌 **（2）按控制方式分类**

| 类型                 | 谁控制流程？                   | 案例              |
| -------------------- | ------------------------------ | ----------------- |
| LLM-Controlled Agent | 一切由 LLM 决定                | AutoGPT、ReAct    |
| Orchestrated Agent   | 由程序主控，LLM 只是说“下一步” | LangGraph         |
| Hybrid Agent         | 规划 + 程序流程图结合          | Devin、企业工作流 |

---

#### 📌 **（3）按智能体数量分类**

| 类型                | 特点       | 场景                 |
| ------------------- | ---------- | -------------------- |
| 单 Agent            | 简单可靠   | 办公助理             |
| 多 Agent            | 分角色协作 | 研发自动化、客服协作 |
| 群体 Agent（Swarm） | 类社会系统 | 金融仿真、游戏 AI    |

---

如果你愿意，我可以把这些扩展分类（按环境 / 按控制 / 按智能体数量）也加入到你的文稿中。

---

### 📊 8. 如何评价一个 Agent？

- **任务成功率**
- **工具调用次数**
- **延迟 / 调用成本**
- **错误恢复能力**
- **安全性与权限合规**
- **可解释性（日志链路）**

---

### 🎯 9. 总结：Agent 的本质

AI Agent 不是“更智能的聊天机器人”，也不是“带工具的 LLM”，而是一个：
能感知、能规划、能行动、能调用工具、能观察、能自我纠错、能持续多轮执行的**智能行动系统**。
随着工具生态、长期记忆技术、验证器、Agent 框架的发展，Agent 很可能成为软件开发的下一代范式：
**从写代码 → 到写意图 从编程 → 到引导**

> **LLM 是大脑
> Agent 是生命体
> 而未来的软件，就是无数 Agent 的协作网络。**

---
